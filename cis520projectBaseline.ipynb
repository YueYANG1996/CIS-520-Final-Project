{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cis520projectBaseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8wxMHp4DEqf",
        "colab_type": "code",
        "outputId": "9a3851da-1585-42f7-e27c-35dccf4cd8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "from keras.applications import vgg16, inception_v3, resnet50, mobilenet\n",
        "from keras import Model\n",
        "import random\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib as plt\n",
        "from os import listdir\n",
        "from pickle import dump\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import Input"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoL_c7sNrvsh",
        "colab_type": "code",
        "outputId": "850c0537-219d-44c7-9688-fe79705fff25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUMNUVLjDJ92",
        "colab_type": "code",
        "outputId": "573dca11-fc98-469c-9cf4-6198d1c677fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# load files\n",
        "!unzip \"/content/drive/My Drive/Flickr8k_Dataset.zip\" -d Flickr8k_Dataset\n",
        "!unzip \"/content/drive/My Drive/Flickr8k_text.zip\" -d Flickr8k_text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Flickr8k_Dataset.zip\n",
            "replace Flickr8k_Dataset/Flicker8k_Dataset/1000268201_693b08cb0e.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/drive/My Drive/Flickr8k_text.zip\n",
            "replace Flickr8k_text/CrowdFlowerAnnotations.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJEZ-m0BqB6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"Flickr8k_text/Flickr_8k.trainImages.txt\",\"r\") as f:\n",
        "    data = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz4lGjN_qkJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL3oX9iGqsUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBDFKZRprJTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLRbsxSUr1Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwK1fhRpsseI",
        "colab_type": "code",
        "outputId": "815e3260-9677-4f3c-9012-4975fe6477dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "# get pretrained model\n",
        "in_layer = Input(shape=(224, 224, 3))\n",
        "vgg = VGG16(weights='imagenet', input_tensor=in_layer)\n",
        "print(vgg.summary())\n",
        "\n",
        "model_output = vgg.get_layer(\"fc2\").output # get output of penultimate layer (fc7)\n",
        "model = Model(inputs=vgg.input, outputs=model_output)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C36htBszsQn1",
        "colab_type": "code",
        "outputId": "a5370fd9-e427-4bb6-f97f-b4ef3ba537a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# extract features from each photo in the directory\n",
        "def extract_features(directory):\n",
        "\t# load the model\n",
        "\t# extract features from each photo\n",
        "\tcount = 0\n",
        "\tnum_images = 8091\n",
        "\tfeatures = dict()\n",
        "\tfor name in listdir(directory):\n",
        "\t# load an image from file\n",
        "\t\tfilename = directory + '/' + name\n",
        "\t\timage = load_img(filename, target_size=(224, 224))\n",
        "\t\t# convert the image pixels to a numpy array\n",
        "\t\timage = img_to_array(image)\n",
        "\t\t# reshape data for the model\n",
        "\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\t\t# prepare the image for the VGG model\n",
        "\t\timage = preprocess_input(image)\n",
        "\t\t# get features\n",
        "\t\tfeature = model.predict(image, verbose=0)\n",
        "\t\t# get image id\n",
        "\t\timage_id = name.split('.')[0]\n",
        "\t\t# store feature\n",
        "\t\tfeatures[image_id] = feature\n",
        "\t\tcount += 1\n",
        "\t\tif count % 100 == 0:\n",
        "\t\t\tprint(\"%i/%i\" % (count, num_images))\n",
        "\treturn features\n",
        "\n",
        "# extract features from all images\n",
        "directory = 'Flickr8k_Dataset/Flicker8k_Dataset'\n",
        "features = extract_features(directory)\n",
        "print('Extracted Features: %d' % len(features))\n",
        "# save to file\n",
        "dump(features, open('features.pkl', 'wb'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/8091\n",
            "200/8091\n",
            "300/8091\n",
            "400/8091\n",
            "500/8091\n",
            "600/8091\n",
            "700/8091\n",
            "800/8091\n",
            "900/8091\n",
            "1000/8091\n",
            "1100/8091\n",
            "1200/8091\n",
            "1300/8091\n",
            "1400/8091\n",
            "1500/8091\n",
            "1600/8091\n",
            "1700/8091\n",
            "1800/8091\n",
            "1900/8091\n",
            "2000/8091\n",
            "2100/8091\n",
            "2200/8091\n",
            "2300/8091\n",
            "2400/8091\n",
            "2500/8091\n",
            "2600/8091\n",
            "2700/8091\n",
            "2800/8091\n",
            "2900/8091\n",
            "3000/8091\n",
            "3100/8091\n",
            "3200/8091\n",
            "3300/8091\n",
            "3400/8091\n",
            "3500/8091\n",
            "3600/8091\n",
            "3700/8091\n",
            "3800/8091\n",
            "3900/8091\n",
            "4000/8091\n",
            "4100/8091\n",
            "4200/8091\n",
            "4300/8091\n",
            "4400/8091\n",
            "4500/8091\n",
            "4600/8091\n",
            "4700/8091\n",
            "4800/8091\n",
            "4900/8091\n",
            "5000/8091\n",
            "5100/8091\n",
            "5200/8091\n",
            "5300/8091\n",
            "5400/8091\n",
            "5500/8091\n",
            "5600/8091\n",
            "5700/8091\n",
            "5800/8091\n",
            "5900/8091\n",
            "6000/8091\n",
            "6100/8091\n",
            "6200/8091\n",
            "6300/8091\n",
            "6400/8091\n",
            "6500/8091\n",
            "6600/8091\n",
            "6700/8091\n",
            "6800/8091\n",
            "6900/8091\n",
            "7000/8091\n",
            "7100/8091\n",
            "7200/8091\n",
            "7300/8091\n",
            "7400/8091\n",
            "7500/8091\n",
            "7600/8091\n",
            "7700/8091\n",
            "7800/8091\n",
            "7900/8091\n",
            "8000/8091\n",
            "Extracted Features: 8091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ackJe_zkAkcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw4dDVlKBZyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFKzUuNetcDg",
        "colab_type": "code",
        "outputId": "9d0e2422-afe2-4d8a-e063-452fae5404f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# loads one description per image\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# extract descriptions for images\n",
        "def load_descriptions(doc):\n",
        "\tmapping = dict()\n",
        "\t# process lines\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\t# take the first token as the image id, the rest as the description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# remove filename from image id\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\t# convert description tokens back to string\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\t# store the first description for each image\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = image_desc\n",
        "\treturn mapping\n",
        "\n",
        "filename = 'Flickr8k_text/Flickr8k.token.txt'\n",
        "doc = load_doc(filename)\n",
        "descriptions = load_descriptions(doc)\n",
        "print('Loaded: %d ' % len(descriptions))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded: 8092 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-MSdJedxGII",
        "colab_type": "code",
        "outputId": "d685c70e-2a97-4e3e-e89d-b9c98991c42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# this version of descriptions has all 5 descriptions for each doc\n",
        "import string\n",
        "# extract descriptions for images\n",
        "def load_full_descriptions(doc):\n",
        "\tmapping = dict()\n",
        "\t# process lines\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\t# take the first token as the image id, the rest as the description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# remove filename from image id\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\t# convert description tokens back to string\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\t# store the first description for each image\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = [image_desc]\n",
        "\t\telse:\n",
        "\t\t\tmapping[image_id].append(image_desc)\n",
        "\treturn mapping\n",
        "\n",
        "# clean description text\n",
        "def clean_full_descriptions(descriptions):\n",
        "# prepare translation table for removing punctuation\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  for key, v in descriptions.items():\n",
        "    all_desc = []\n",
        "    for desc in v:\n",
        "      # tokenize\n",
        "      desc = desc.split()\n",
        "      # convert to lower case\n",
        "      desc = [word.lower() for word in desc]\n",
        "      # remove punctuation from each token\n",
        "      desc = [w.translate(table) for w in desc]\n",
        "      # remove hanging 's' and 'a'\n",
        "      desc = [word for word in desc if len(word)>1]\n",
        "      # store as string\n",
        "      all_desc.append(' '.join(desc))\n",
        "    descriptions[key] = all_desc\n",
        "\n",
        "filename = 'Flickr8k_text/Flickr8k.token.txt'\n",
        "# load descriptions\n",
        "doc = load_doc(filename)\n",
        "# parse descriptions\n",
        "full_descriptions = load_full_descriptions(doc)\n",
        "print('Loaded: %d ' % len(full_descriptions))\n",
        "# clean descriptions\n",
        "clean_full_descriptions(full_descriptions)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded: 8092 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmITzgSxzG2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1uBoiSexJxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate splits\n",
        "X_train, X_test, y_train, y_test, y_test_multiple = [], [], [], [], []\n",
        "\n",
        "files = [\"Flickr8k_text/Flickr_8k.trainImages.txt\",\n",
        "         \"Flickr8k_text/Flickr_8k.devImages.txt\",\n",
        "         \"Flickr8k_text/Flickr_8k.testImages.txt\"]\n",
        "for idx, f_name in enumerate(files):\n",
        "  f = open(f_name, 'r')\n",
        "  for line in f:\n",
        "    image_id = line.strip()[:-4]\n",
        "    if idx == 0 or idx == 1:\n",
        "      X_train.append(features[image_id][0])\n",
        "      y_train.append(descriptions[image_id])\n",
        "    else:\n",
        "      X_test.append(features[image_id][0])\n",
        "      y_test.append(descriptions[image_id])\n",
        "      y_test_multiple.append(full_descriptions[image_id])\n",
        "  f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhHlMbNH16ur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZVxN1b1zNrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz6bPWI00Q5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLoGMu7fze6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "38792c67-35af-4a18-e659-7214a1471942"
      },
      "source": [
        "i = 1\n",
        "clf = KNeighborsClassifier(n_neighbors=i)\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J_gNzWusPQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNcuxcZG0TQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chOXOMAE1CTE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnyuKd3E0kLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJew7V7e1E1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-ilvArZ1vO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nidr1sy31w1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2e2a1880-64df-4adb-c188-3c51f0b622cb"
      },
      "source": [
        "y_test_multiple[0]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the dogs are in the snow in front of fence',\n",
              " 'the dogs play on the snow',\n",
              " 'two brown dogs playfully fight in the snow',\n",
              " 'two brown dogs wrestle in the snow',\n",
              " 'two dogs playing in the snow']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VmYdze15RAb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "55328fba-5e5a-4212-ac18-4c7a13268844"
      },
      "source": [
        "references = [[['this', 'is', 'a', 'test'], ['this', 'is' 'test']]]\n",
        "count = 0\n",
        "score = 0\n",
        "for y_true, y_hat in zip(y_test, y_pred):\n",
        "  references = [[y_true.lower().split()]]\n",
        "  candidates = [y_hat.lower().split()]\n",
        "  score += corpus_bleu(references, candidates)\n",
        "  count += 1\n",
        "print(score / count)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4763962696496128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B76mwz_kJ5Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsZFLg5T5yZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzmvRfwy54mD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMIOs2bR556s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}